"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[99355],{15680:(e,n,a)=>{a.d(n,{xA:()=>g,yg:()=>c});var t=a(96540);function i(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function r(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}function l(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?r(Object(a),!0).forEach((function(n){i(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function o(e,n){if(null==e)return{};var a,t,i=function(e,n){if(null==e)return{};var a,t,i={},r=Object.keys(e);for(t=0;t<r.length;t++)a=r[t],n.indexOf(a)>=0||(i[a]=e[a]);return i}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(t=0;t<r.length;t++)a=r[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var s=t.createContext({}),p=function(e){var n=t.useContext(s),a=n;return e&&(a="function"==typeof e?e(n):l(l({},n),e)),a},g=function(e){var n=p(e.components);return t.createElement(s.Provider,{value:n},e.children)},m={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},d=t.forwardRef((function(e,n){var a=e.components,i=e.mdxType,r=e.originalType,s=e.parentName,g=o(e,["components","mdxType","originalType","parentName"]),d=p(a),c=i,y=d["".concat(s,".").concat(c)]||d[c]||m[c]||r;return a?t.createElement(y,l(l({ref:n},g),{},{components:a})):t.createElement(y,l({ref:n},g))}));function c(e,n){var a=arguments,i=n&&n.mdxType;if("string"==typeof e||i){var r=a.length,l=new Array(r);l[0]=d;var o={};for(var s in n)hasOwnProperty.call(n,s)&&(o[s]=n[s]);o.originalType=e,o.mdxType="string"==typeof e?e:i,l[1]=o;for(var p=2;p<r;p++)l[p]=a[p];return t.createElement.apply(null,l)}return t.createElement.apply(null,a)}d.displayName="MDXCreateElement"},54255:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>g,contentTitle:()=>s,default:()=>c,frontMatter:()=>o,metadata:()=>p,toc:()=>m});var t=a(58168),i=a(98587),r=(a(96540),a(15680)),l=["components"],o={id:"gator",title:"The gator CLI"},s=void 0,p={unversionedId:"gator",id:"gator",title:"The gator CLI",description:"Feature State: Gatekeeper version v3.11+ (beta)",source:"@site/docs/gator.md",sourceDirName:".",slug:"/gator",permalink:"/gatekeeper/website/docs/next/gator",draft:!1,editUrl:"https://github.com/open-policy-agent/gatekeeper/edit/master/website/docs/gator.md",tags:[],version:"current",frontMatter:{id:"gator",title:"The gator CLI"},sidebar:"docs",previous:{title:"Validating Workload Resources using ExpansionTemplate",permalink:"/gatekeeper/website/docs/next/expansion"},next:{title:"Working with Workload Resources",permalink:"/gatekeeper/website/docs/next/workload-resources"}},g={},m=[{value:"Installation",id:"installation",level:2},{value:"The <code>gator test</code> subcommand",id:"the-gator-test-subcommand",level:2},{value:"Usage",id:"usage",level:3},{value:"Specifying inputs",id:"specifying-inputs",level:4},{value:"Exit Codes",id:"exit-codes",level:4},{value:"Enforcement Actions",id:"enforcement-actions",level:5},{value:"Output Formatting",id:"output-formatting",level:4},{value:"The <code>gator verify</code> subcommand",id:"the-gator-verify-subcommand",level:2},{value:"Writing Test Suites",id:"writing-test-suites",level:3},{value:"Suites",id:"suites",level:3},{value:"Tests",id:"tests",level:3},{value:"Cases",id:"cases",level:3},{value:"Usage",id:"usage-1",level:3},{value:"Validating Generated Resources with ExpansionTemplates",id:"validating-generated-resources-with-expansiontemplates",level:3},{value:"Validating Metadata-Based Constraint Templates",id:"validating-metadata-based-constraint-templates",level:3},{value:"The <code>gator expand</code> subcommand",id:"the-gator-expand-subcommand",level:2},{value:"Usage",id:"usage-2",level:3},{value:"Non default namespace example",id:"non-default-namespace-example",level:4},{value:"The <code>gator sync test</code> subcommand",id:"the-gator-sync-test-subcommand",level:2},{value:"Usage",id:"usage-3",level:3},{value:"Specifying Inputs",id:"specifying-inputs-1",level:4},{value:"Exit Codes",id:"exit-codes-1",level:4},{value:"The <code>gator bench</code> subcommand",id:"the-gator-bench-subcommand",level:2},{value:"Usage",id:"usage-4",level:3},{value:"Flags",id:"flags",level:4},{value:"Examples",id:"examples",level:3},{value:"Basic Benchmark",id:"basic-benchmark",level:4},{value:"Concurrent Benchmarking",id:"concurrent-benchmarking",level:4},{value:"Compare Rego vs CEL Engines",id:"compare-rego-vs-cel-engines",level:4},{value:"Memory Profiling",id:"memory-profiling",level:4},{value:"Save and Compare Baselines",id:"save-and-compare-baselines",level:4},{value:"CI/CD Integration",id:"cicd-integration",level:3},{value:"GitHub Actions Example",id:"github-actions-example",level:4},{value:"Exit Codes",id:"exit-codes-2",level:4},{value:"Understanding Metrics",id:"understanding-metrics",level:3},{value:"Setup Duration Breakdown",id:"setup-duration-breakdown",level:4},{value:"Performance Guidance",id:"performance-guidance",level:4},{value:"Performance Characteristics",id:"performance-characteristics",level:3},{value:"CEL vs Rego",id:"cel-vs-rego",level:4},{value:"Concurrency Scaling",id:"concurrency-scaling",level:4},{value:"Benchmarking Best Practices",id:"benchmarking-best-practices",level:4},{value:"Interpreting Results",id:"interpreting-results",level:4},{value:"Bundling Policy into OCI Artifacts",id:"bundling-policy-into-oci-artifacts",level:2},{value:"Gotchas",id:"gotchas",level:2},{value:"Duplicate violation messages",id:"duplicate-violation-messages",level:3},{value:"Matching is case-sensitive",id:"matching-is-case-sensitive",level:3},{value:"Referential constraints and Namespace-scoped resources",id:"referential-constraints-and-namespace-scoped-resources",level:3},{value:"Platform Compatibility",id:"platform-compatibility",level:2}],d={toc:m};function c(e){var n=e.components,a=(0,i.A)(e,l);return(0,r.yg)("wrapper",(0,t.A)({},d,a,{components:n,mdxType:"MDXLayout"}),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"Feature State"),": Gatekeeper version v3.11+ (beta)"),(0,r.yg)("p",null,"The ",(0,r.yg)("inlineCode",{parentName:"p"},"gator")," CLI is a tool for evaluating Gatekeeper ConstraintTemplates and\nConstraints in a local environment."),(0,r.yg)("h2",{id:"installation"},"Installation"),(0,r.yg)("p",null,"To install ",(0,r.yg)("inlineCode",{parentName:"p"},"gator"),", you may either\n",(0,r.yg)("a",{parentName:"p",href:"https://github.com/open-policy-agent/gatekeeper/releases"},"download the binary"),"\nrelevant to your system or build it directly from source. On macOS and Linux,\nyou can also install ",(0,r.yg)("inlineCode",{parentName:"p"},"gator")," using ",(0,r.yg)("a",{parentName:"p",href:"https://brew.sh"},"Homebrew"),"."),(0,r.yg)("p",null,"To build from source:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},"go install github.com/open-policy-agent/gatekeeper/v3/cmd/gator@master\n")),(0,r.yg)("admonition",{type:"note"},(0,r.yg)("p",{parentName:"admonition"},(0,r.yg)("inlineCode",{parentName:"p"},"go install")," of ",(0,r.yg)("inlineCode",{parentName:"p"},"gator")," requires Gatekeeper ",(0,r.yg)("inlineCode",{parentName:"p"},"master")," branch or ",(0,r.yg)("inlineCode",{parentName:"p"},"v3.16.0")," and later.")),(0,r.yg)("p",null,"Install with Homebrew:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},"brew install gator\n")),(0,r.yg)("h2",{id:"the-gator-test-subcommand"},"The ",(0,r.yg)("inlineCode",{parentName:"h2"},"gator test")," subcommand"),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"gator test")," allows users to test a set of Kubernetes objects against a set of\nTemplates and Constraints. The command returns violations when found and\ncommunicates success or failure via its exit status. This command will also\nattempt to expand any resources passed in if a supplied ",(0,r.yg)("inlineCode",{parentName:"p"},"ExpansionTemplate"),"\nmatches these resources."),(0,r.yg)("p",null,"Note: The ",(0,r.yg)("inlineCode",{parentName:"p"},"gator verify")," command was first called ",(0,r.yg)("inlineCode",{parentName:"p"},"gator test"),". These names were\nchanged to better align ",(0,r.yg)("inlineCode",{parentName:"p"},"gator")," with other projects in the open-policy-agent\nspace."),(0,r.yg)("h3",{id:"usage"},"Usage"),(0,r.yg)("admonition",{type:"note"},(0,r.yg)("p",{parentName:"admonition"},"Flag ",(0,r.yg)("inlineCode",{parentName:"p"},"enable-k8s-native-validation"),' enables ConstraintTemplate containing "validating admission policy styled CEL". By default, this flag is enabled and set to ',(0,r.yg)("inlineCode",{parentName:"p"},"true"),".")),(0,r.yg)("h4",{id:"specifying-inputs"},"Specifying inputs"),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"gator test")," supports inputs through the ",(0,r.yg)("inlineCode",{parentName:"p"},"--filename")," and ",(0,r.yg)("inlineCode",{parentName:"p"},"--image")," flags, and\nvia stdin. The three methods of input can be used in combination or individually. The ",(0,r.yg)("inlineCode",{parentName:"p"},"--filename")," and ",(0,r.yg)("inlineCode",{parentName:"p"},"--image")," flags are repeatable."),(0,r.yg)("p",null,"The ",(0,r.yg)("inlineCode",{parentName:"p"},"--filename")," flag can specify a single file or a directory. If a file is\nspecified, that file must end in one of the following extensions: ",(0,r.yg)("inlineCode",{parentName:"p"},".json"),",\n",(0,r.yg)("inlineCode",{parentName:"p"},".yaml"),", ",(0,r.yg)("inlineCode",{parentName:"p"},".yml"),". Directories will be walked, and any files of extensions other\nthan the aforementioned three will be skipped."),(0,r.yg)("p",null,"For example, to test a manifest (piped via stdin) against a folder of policies:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},"cat my-manifest.yaml | gator test --filename=template-and-constraints/\n")),(0,r.yg)("p",null,"Or you can specify both as flags:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},"gator test -f=my-manifest.yaml -f=templates-and-constraints/\n")),(0,r.yg)("blockquote",null,(0,r.yg)("p",{parentName:"blockquote"},"\u2757The ",(0,r.yg)("inlineCode",{parentName:"p"},"--image")," flag is in ",(0,r.yg)("em",{parentName:"p"},"alpha")," stage.")),(0,r.yg)("p",null,"The ",(0,r.yg)("inlineCode",{parentName:"p"},"--image")," flag specifies a content addressable OCI artifact containing\npolicy files. The image(s) will be copied into the local filesystem in a\ntemporary directory, the location of which can be overridden with\nthe ",(0,r.yg)("inlineCode",{parentName:"p"},"--tempdir"),"\nflag. Only files with the aforementioned extensions will be processed. For\ninformation on how to create OCI policy bundles, see\nthe ",(0,r.yg)("a",{parentName:"p",href:"#bundling-policy-into-oci-artifacts"},"Bundling Policy into OCI Artifacts"),"\nsection."),(0,r.yg)("p",null,"For example, to test a manifest (piped via stdin) against an OCI Artifact\ncontaining policies:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},"cat my-manifest.yaml | gator test --image=localhost:5000/gator/template-library:v1 \\\n  --image=localhost:5000/gator/constraints:v1\n")),(0,r.yg)("p",null,"The ",(0,r.yg)("inlineCode",{parentName:"p"},"--deny-only")," flag will only output violations about denied constraints, not the ones using ",(0,r.yg)("inlineCode",{parentName:"p"},"warn")," enforcement action."),(0,r.yg)("admonition",{type:"note"},(0,r.yg)("p",{parentName:"admonition"},(0,r.yg)("inlineCode",{parentName:"p"},"--deny-only")," flag is available after Gatekeeper 3.19.")),(0,r.yg)("h4",{id:"exit-codes"},"Exit Codes"),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"gator test")," will return a ",(0,r.yg)("inlineCode",{parentName:"p"},"0")," exit status when the objects, Templates, and\nConstraints are successfully ingested, no errors occur during evaluation, and no\nviolations are found."),(0,r.yg)("p",null,"An error during evaluation, for example a failure to read a file, will result in\na ",(0,r.yg)("inlineCode",{parentName:"p"},"1")," exit status with an error message printed to stderr."),(0,r.yg)("p",null,"Policy violations will generate a ",(0,r.yg)("inlineCode",{parentName:"p"},"1")," exit status as well, but violation\ninformation will be printed to stdout."),(0,r.yg)("h5",{id:"enforcement-actions"},"Enforcement Actions"),(0,r.yg)("p",null,"While violation data will always be returned when an object is found to be\nviolating a Constraint, the exit status can vary. A constraint with\n",(0,r.yg)("inlineCode",{parentName:"p"},'spec.enforcementAction: ""')," or ",(0,r.yg)("inlineCode",{parentName:"p"},"spec.enforcementAction: deny")," will produce a\n",(0,r.yg)("inlineCode",{parentName:"p"},"1")," exit code, but other enforcement actions like ",(0,r.yg)("inlineCode",{parentName:"p"},"dryrun")," will not. This is\nmeant to make the exit code of ",(0,r.yg)("inlineCode",{parentName:"p"},"1")," consistent with rejection of the object by\nGatekeeper's webhook. A Constraint set to ",(0,r.yg)("inlineCode",{parentName:"p"},"warn")," would not trigger a rejection\nin the webhook, but ",(0,r.yg)("em",{parentName:"p"},"would")," produce a violation message. The same is true for\nthat constraint when used in ",(0,r.yg)("inlineCode",{parentName:"p"},"gator test"),"."),(0,r.yg)("h4",{id:"output-formatting"},"Output Formatting"),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"gator test")," supports a ",(0,r.yg)("inlineCode",{parentName:"p"},"--output")," flag that allows the user to specify a\nstructured data format for the violation data. This information is printed to\nstdout."),(0,r.yg)("p",null,"The allowed values are ",(0,r.yg)("inlineCode",{parentName:"p"},"yaml")," and ",(0,r.yg)("inlineCode",{parentName:"p"},"json"),", specified like:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},"gator test --filename=manifests-and-policies/ --output=json\n")),(0,r.yg)("h2",{id:"the-gator-verify-subcommand"},"The ",(0,r.yg)("inlineCode",{parentName:"h2"},"gator verify")," subcommand"),(0,r.yg)("admonition",{type:"note"},(0,r.yg)("p",{parentName:"admonition"},"Flag ",(0,r.yg)("inlineCode",{parentName:"p"},"enable-k8s-native-validation"),' enables ConstraintTemplate containing "validating admission policy styled CEL". By default, this flag is enabled and set to ',(0,r.yg)("inlineCode",{parentName:"p"},"true"),".")),(0,r.yg)("h3",{id:"writing-test-suites"},"Writing Test Suites"),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"gator verify")," organizes tests into three levels: Suites, Tests, and Cases:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"A Suite is a file which defines Tests."),(0,r.yg)("li",{parentName:"ul"},"A Test declares a ConstraintTemplate, a Constraint, an ExpansionTemplate (optional), and Cases to test the\nConstraint."),(0,r.yg)("li",{parentName:"ul"},"A Case defines an object to validate and whether the object is expected to\npass validation.")),(0,r.yg)("p",null,"Any file paths declared in a Suite are assumed to be relative to the Suite\nitself. Absolute paths are not allowed. Thus, it is possible to move around a\ndirectory containing a Suite, and the files it uses for tests."),(0,r.yg)("h3",{id:"suites"},"Suites"),(0,r.yg)("p",null,(0,r.yg)("a",{parentName:"p",href:"https://github.com/open-policy-agent/gatekeeper-library/blob/8765ec11c12a523688ed77485c7a458df84266d6/library/general/allowedrepos/suite.yaml"},"An example Suite file"),"\n."),(0,r.yg)("p",null,"To be valid, a Suite file must declare:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},"kind: Suite\napiVersion: test.gatekeeper.sh/v1alpha1\n")),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"gator verify")," silently ignores files which do not declare these. A Suite may\ndeclare multiple Tests, each containing different Templates and Constraints.\nEach Test in a Suite is independent."),(0,r.yg)("h3",{id:"tests"},"Tests"),(0,r.yg)("p",null,"Each Suite contains a list of Tests under the ",(0,r.yg)("inlineCode",{parentName:"p"},"tests")," field."),(0,r.yg)("p",null,"A Test compiles a ConstraintTemplate, and instantiates a Constraint for the\nConstraintTemplate. It is an error for the Constraint to have a different type\nthan that defined in the ConstraintTemplate spec.crd.spec.names.kind, or for the\nConstraintTemplate to not compile."),(0,r.yg)("p",null,"A Test can also optionally compile an ExpansionTemplate."),(0,r.yg)("h3",{id:"cases"},"Cases"),(0,r.yg)("p",null,"Each Test contains a list of Cases under the ",(0,r.yg)("inlineCode",{parentName:"p"},"cases")," field."),(0,r.yg)("p",null,"A Case validates an object against a Constraint. The case may specify that the\nobject is expected to pass or fail validation, and may make assertions about the\nreturned violations (if any)."),(0,r.yg)("p",null,"A Case must specify ",(0,r.yg)("inlineCode",{parentName:"p"},"assertions")," and whether it expects violations. The simplest\nway to declare this is:"),(0,r.yg)("p",null,"The Case expects at least one violation:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},"assertions:\n- violations: yes\n")),(0,r.yg)("p",null,"The Case expects no violations:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},"assertions:\n- violations: no\n")),(0,r.yg)("p",null,"Assertions contain the following fields, acting as conditions for each assertion\nto check."),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"violations"),' is either "yes", "no", or a non-negative integer.',(0,r.yg)("ul",{parentName:"li"},(0,r.yg)("li",{parentName:"ul"},'If "yes", at least one violation must otherwise match the assertion.'),(0,r.yg)("li",{parentName:"ul"},'If "no", then no violation messages must otherwise match the assertion.'),(0,r.yg)("li",{parentName:"ul"},'If a nonnegative integer, then exactly that many violations must match.\nDefaults to "yes".'))),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"message")," is a regular expression used to match the violation message. ",(0,r.yg)("inlineCode",{parentName:"li"},"message"),"\nis case-sensitive. If not specified or explicitly set to empty string, all\nmessages returned by the Constraint are considered matching.")),(0,r.yg)("p",null,"A Case may specify multiple assertions. For example:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},"  - name: both-disallowed\n    object: samples/repo-must-be-openpolicyagent/disallowed_both.yaml\n    assertions:\n    - violations: 2\n    - message: initContainer\n      violations: 1\n    - message: container\n      violations: 1\n")),(0,r.yg)("p",null,"This Case specifies:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"There are exactly two violations."),(0,r.yg)("li",{parentName:"ul"},'There is exactly one violation containing "initContainer".'),(0,r.yg)("li",{parentName:"ul"},'There is exactly one violation containing "container".')),(0,r.yg)("p",null,"It is valid to assert that no violations match a specified message. For example,\nthe below is valid:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},"- violations: yes\n- violations: no\n  message: foobar\n")),(0,r.yg)("p",null,'This Case specifies that there is at least one violation, and no violations\ncontain the string "foobar".'),(0,r.yg)("p",null,"A Case may specify ",(0,r.yg)("inlineCode",{parentName:"p"},"inventory"),", which is a list of paths to files containing\nKubernetes objects to put in ",(0,r.yg)("inlineCode",{parentName:"p"},"data.inventory")," for testing referential\nconstraints."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},"inventory:\n- samples/data_objects.yaml\n")),(0,r.yg)("p",null,"More examples of working ",(0,r.yg)("inlineCode",{parentName:"p"},"gator verify")," suites are available in the\n",(0,r.yg)("a",{parentName:"p",href:"https://github.com/open-policy-agent/gatekeeper-library/tree/master/library"},"gatekeeper-library"),"\nrepository."),(0,r.yg)("h3",{id:"usage-1"},"Usage"),(0,r.yg)("p",null,"To run a specific suite:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre"},"gator verify suite.yaml\n")),(0,r.yg)("p",null,"To run all suites in the current directory and all child directories recursively"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},"gator verify ./...\n")),(0,r.yg)("p",null,"To only run tests whose full names contain a match for a regular expression, use\nthe ",(0,r.yg)("inlineCode",{parentName:"p"},"run")," flag:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},'gator verify path/to/suites/... --run "disallowed"\n')),(0,r.yg)("h3",{id:"validating-generated-resources-with-expansiontemplates"},"Validating Generated Resources with ExpansionTemplates"),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"gator verify")," may be used along with expansion templates to validate generated resources. The expansion template is optionally declared at the test level. If an expansion template is set for a test, gator will attempt to expand each object under the test. The violations for the parent object & its expanded resources will be aggregated."),(0,r.yg)("p",null,"Example for declaring an expansion template in a Gator Suite:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: test.gatekeeper.sh/v1alpha1\nkind: Suite\ntests:\n- name: expansion\n  template: template.yaml\n  constraint: constraint.yaml\n  expansion: expansion.yaml\n  cases:\n  - name: example-expand\n    object: deployment.yaml\n    assertions:\n    - violations: yes\n")),(0,r.yg)("h3",{id:"validating-metadata-based-constraint-templates"},"Validating Metadata-Based Constraint Templates"),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"gator verify")," may be used with an ",(0,r.yg)("a",{parentName:"p",href:"https://pkg.go.dev/k8s.io/kubernetes/pkg/apis/admission#AdmissionReview"},(0,r.yg)("inlineCode",{parentName:"a"},"AdmissionReview")),"\nobject to test your constraints. This can be helpful to simulate a certain operation (",(0,r.yg)("inlineCode",{parentName:"p"},"CREATE"),", ",(0,r.yg)("inlineCode",{parentName:"p"},"UPDATE"),", ",(0,r.yg)("inlineCode",{parentName:"p"},"DELETE"),", etc.)\nor ",(0,r.yg)("a",{parentName:"p",href:"https://pkg.go.dev/k8s.io/kubernetes@v1.25.3/pkg/apis/authentication#UserInfo"},(0,r.yg)("inlineCode",{parentName:"a"},"UserInfo"))," metadata.\nRecall that the ",(0,r.yg)("inlineCode",{parentName:"p"},"input.review.user")," can be accessed in the Rego code (see ",(0,r.yg)("a",{parentName:"p",href:"/gatekeeper/website/docs/next/howto#input-review"},"Input Review")," for more guidance). The ",(0,r.yg)("inlineCode",{parentName:"p"},"AdmissionReview")," object can be specified where you would specify the object under test above:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},"  - name: both-disallowed\n    object: path/to/test_admission_review.yaml\n    assertions:\n    - violations: 1\n")),(0,r.yg)("p",null,"Example for testing the ",(0,r.yg)("inlineCode",{parentName:"p"},"UserInfo")," metadata:"),(0,r.yg)("p",null,"AdmissionReview, ConstraintTemplate, Constraint:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},'kind: AdmissionReview\napiVersion: admission.k8s.io/v1beta1\nrequest:\n  operation: "UPDATE"\n  userInfo:\n    username: "system:foo"\n  object:\n    kind: Pod\n    labels:\n      - app: "bar"\n---\nkind: ConstraintTemplate\napiVersion: templates.gatekeeper.sh/v1\nmetadata:\n  name: validateuserinfo\nspec:\n  crd:\n    spec:\n      names:\n        kind: ValidateUserInfo\n  targets:\n    - target: admission.k8s.gatekeeper.sh\n      rego: |\n        package k8svalidateuserinfo\n        violation[{"msg": msg}] {\n          username := input.review.userInfo.username\n          not startswith(username, "system:")\n          msg := sprintf("username is not allowed to perform this operation: %v", [username])\n        }\n---\nkind: ValidateUserInfo\napiVersion: constraints.gatekeeper.sh/v1\nmetadata:\n  name: always-validate\n')),(0,r.yg)("p",null,"Gator Suite:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: test.gatekeeper.sh/v1alpha1\nkind: Suite\ntests:\n- name: userinfo\n  template: template.yaml\n  constraint: constraint.yaml\n  cases:\n  - name: system-user\n    object: admission-review.yaml\n    assertions:\n    - violations: no\n")),(0,r.yg)("p",null,"Note for ",(0,r.yg)("inlineCode",{parentName:"p"},"DELETE")," operation, the ",(0,r.yg)("inlineCode",{parentName:"p"},"oldObject")," should be the object being deleted:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},'kind: AdmissionReview\napiVersion: admission.k8s.io/v1beta1\nrequest:\n  operation: "DELETE"\n  userInfo:\n    username: "system:foo"\n  oldObject:\n    kind: Pod\n    labels:\n      - app: "bar"\n')),(0,r.yg)("p",null,"Note that ",(0,r.yg)("a",{parentName:"p",href:"/gatekeeper/website/docs/next/audit"},(0,r.yg)("inlineCode",{parentName:"a"},"audit"))," or ",(0,r.yg)("inlineCode",{parentName:"p"},"gator test")," are different enforcement points and they don't have the ",(0,r.yg)("inlineCode",{parentName:"p"},"AdmissionReview")," request metadata."),(0,r.yg)("p",null,"Run ",(0,r.yg)("inlineCode",{parentName:"p"},"gator verify --help")," for more information."),(0,r.yg)("h2",{id:"the-gator-expand-subcommand"},"The ",(0,r.yg)("inlineCode",{parentName:"h2"},"gator expand")," subcommand"),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"gator expand")," allows users to test the behavior of their Expansion configs. The\ncommand accepts a file or directory containing the expansion configs, which\nshould include the resource(s) under test, the ",(0,r.yg)("inlineCode",{parentName:"p"},"ExpansionTemplate"),"(s), and\noptionally any Mutation CRs. The command will output a manifest containing the\nexpanded resources."),(0,r.yg)("p",null,"If the mutators or constraints use ",(0,r.yg)("inlineCode",{parentName:"p"},"spec.match.namespaceSelector"),", the namespace the resource\nbelongs to must be supplied in order to correctly evaluate the match criteria.\nIf a resource is specified for expansion but its non-default namespace is not\nsupplied, the command will exit 1. See the ",(0,r.yg)("a",{parentName:"p",href:"#non-default-namespace-example"},"non default namespace example")," below."),(0,r.yg)("h3",{id:"usage-2"},"Usage"),(0,r.yg)("p",null,"Similar to ",(0,r.yg)("inlineCode",{parentName:"p"},"gator test"),", ",(0,r.yg)("inlineCode",{parentName:"p"},"gator expand")," expects a ",(0,r.yg)("inlineCode",{parentName:"p"},"--filename")," or ",(0,r.yg)("inlineCode",{parentName:"p"},"--image"),"\nflag. The flags can be used individually, in combination, and/or repeated."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},'gator expand --filename="manifest.yaml" \u2013filename="expansion-policy/"\n')),(0,r.yg)("p",null,"Or, using an OCI Artifact for the expansion configuration:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},'gator expand --filename="my-deployment.yaml" --image=localhost:5000/gator/expansion-policy:v1\n')),(0,r.yg)("p",null,"By default, ",(0,r.yg)("inlineCode",{parentName:"p"},"gator expand")," will output to stdout, but a ",(0,r.yg)("inlineCode",{parentName:"p"},"\u2013outputfile")," flag can be\nspecified to write the results to a file."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},'gator expand --filename="manifest.yaml" \u2013outputfile="results.yaml"\n')),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"gator expand")," can output in ",(0,r.yg)("inlineCode",{parentName:"p"},"yaml")," or ",(0,r.yg)("inlineCode",{parentName:"p"},"json")," (default is ",(0,r.yg)("inlineCode",{parentName:"p"},"yaml"),")."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},'gator expand --filename="manifest.yaml" \u2013format="json"\n')),(0,r.yg)("p",null,"See ",(0,r.yg)("inlineCode",{parentName:"p"},"gator expand \u2013help")," for more details. ",(0,r.yg)("inlineCode",{parentName:"p"},"gator expand")," will exit 1 if there\nis a problem parsing the configs or expanding the resources."),(0,r.yg)("h4",{id:"non-default-namespace-example"},"Non default namespace example"),(0,r.yg)("p",null,"This is an example setup where we include a ",(0,r.yg)("inlineCode",{parentName:"p"},"namespace")," in a ",(0,r.yg)("inlineCode",{parentName:"p"},"manifest.yaml")," that we plan on passing to ",(0,r.yg)("inlineCode",{parentName:"p"},"gator expand"),"."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: expansion.gatekeeper.sh/v1alpha1\nkind: ExpansionTemplate\nmetadata:\n  name: expand-deployments\nspec:\n  applyTo:\n  - groups: [ "apps" ]\n    kinds: [ "Deployment" ]\n    versions: [ "v1" ]\n  templateSource: "spec.template"\n  generatedGVK:\n    kind: "Pod"\n    group: ""\n    version: "v1"\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  namespace: my-ns\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n        args:\n        - "/bin/sh"\n---\napiVersion: mutations.gatekeeper.sh/v1alpha1\nkind: Assign\nmetadata:\n  name: always-pull-image\nspec:\n  applyTo:\n  - groups: [ "" ]\n    kinds: [ "Pod" ]\n    versions: [ "v1" ]\n  location: "spec.containers[name: *].imagePullPolicy"\n  parameters:\n    assign:\n      value: "Always"\n  match:\n    source: "Generated"\n    scope: Namespaced\n    kinds:\n    - apiGroups: [ ]\n      kinds: [ ]\n    namespaceSelector:\n      matchExpressions:\n        - key: admission.gatekeeper.sh/ignore\n          operator: DoesNotExist\n---\n# notice this file is providing the non default namespace `my-ns`\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: my-ns\n')),(0,r.yg)("p",null,"Calling ",(0,r.yg)("inlineCode",{parentName:"p"},"gator expand --filename=manifest.yaml")," will produce the following output:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    app: nginx\n  name: nginx-deployment-pod\n  namespace: my-ns\nspec:\n  containers:\n  - args:\n    - /bin/sh\n    image: nginx:1.14.2\n    imagePullPolicy: Always\n    name: nginx\n    ports:\n    - containerPort: 80\n")),(0,r.yg)("p",null,"However, not including the ",(0,r.yg)("inlineCode",{parentName:"p"},"namespace")," definition in the call to ",(0,r.yg)("inlineCode",{parentName:"p"},"gator expand")," will exit with a status code of 1 and error out with:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre"},"error expanding resources: error expanding resource nginx-deployment: failed to mutate resultant resource nginx-deployment-pod: matching for mutator Assign.mutations.gatekeeper.sh /always-pull-image failed for  Pod my-ns nginx-deployment-pod: failed to run Match criteria: namespace selector for namespace-scoped object but missing Namespace\n")),(0,r.yg)("h2",{id:"the-gator-sync-test-subcommand"},"The ",(0,r.yg)("inlineCode",{parentName:"h2"},"gator sync test")," subcommand"),(0,r.yg)("p",null,"Certain templates require ",(0,r.yg)("a",{parentName:"p",href:"/gatekeeper/website/docs/next/sync"},"replicating data")," into OPA to enable correct evaluation. These templates can use the annotation ",(0,r.yg)("inlineCode",{parentName:"p"},"metadata.gatekeeper.sh/requires-sync-data")," to indicate which resources need to be synced. The annotation contains a json object representing a list of requirements, each of which contains a list of one or more GVK clauses forming an equivalence set of interchangeable GVKs. Each of these clauses has ",(0,r.yg)("inlineCode",{parentName:"p"},"groups"),", ",(0,r.yg)("inlineCode",{parentName:"p"},"versions"),", and ",(0,r.yg)("inlineCode",{parentName:"p"},"kinds")," fields; any group-version-kind combination within a clause within a requirement should be considered sufficient to satisfy that requirement. For example (comments added for clarity):"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre"},'[\n  [ // Requirement 1\n    { // Clause 1\n      "groups": ["group1", group2"]\n      "versions": ["version1", "version2", "version3"]\n      "kinds": ["kind1", "kind2"]\n    },\n    { // Clause 2\n      "groups": ["group3", group4"]\n      "versions": ["version3", "version4"]\n      "kinds": ["kind3", "kind4"]\n    }\n  ],\n  [ // Requirement 2\n    { // Clause 1\n      "groups": ["group5"]\n      "versions": ["version5"]\n      "kinds": ["kind5"]\n    }\n  ]\n]\n')),(0,r.yg)("p",null,"This annotation contains two requirements. Requirement 1 contains two clauses. Syncing resources of group1, version3, kind1 (drawn from clause 1) would be sufficient to fulfill Requirement 1. So, too, would syncing resources of group3, version3, kind4 (drawn from clause 2). Syncing resources of group1, version1, and kind3 would not be, however."),(0,r.yg)("p",null,"Requirement 2 is simpler: it denotes that group5, version5, kind5 must be synced for the policy to work properly."),(0,r.yg)("p",null,"This template annotation is descriptive, not prescriptive. The prescription of which resources to sync is done in ",(0,r.yg)("inlineCode",{parentName:"p"},"SyncSet")," resources and/or the Gatekeeper ",(0,r.yg)("inlineCode",{parentName:"p"},"Config")," resource. The management of these various requirements can get challenging as the number of templates requiring replicated data increases."),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"gator sync test")," aims to mitigate this challenge by enabling the user to check that their sync configuration is correct. The user passes in a set of Constraint Templates, GVK Manifest listing GVKs supported by the cluster, SyncSets, and/or a Gatekeeper Config, and the command will determine which requirements enumerated by the Constraint Templates are unfulfilled by the cluster and SyncSet(s)/Config."),(0,r.yg)("h3",{id:"usage-3"},"Usage"),(0,r.yg)("h4",{id:"specifying-inputs-1"},"Specifying Inputs"),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"gator sync test")," expects a ",(0,r.yg)("inlineCode",{parentName:"p"},"--filename")," or ",(0,r.yg)("inlineCode",{parentName:"p"},"--image")," flag, or input from stdin. The flags can be used individually, in combination, and/or repeated."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre"},'gator sync test --filename="template.yaml" \u2013-filename="syncsets/" --filename="manifest.yaml"\n')),(0,r.yg)("p",null,"Or, using an OCI Artifact containing templates as described previously:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre"},'gator sync test --filename="config.yaml" --image=localhost:5000/gator/template-library:v1\n')),(0,r.yg)("p",null,"The manifest of GVKs supported by the cluster should be passed as a GVKManifest resource (CRD visible under the apis directory in the repo):"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre"},'apiVersion: gvkmanifest.gatekeeper.sh/v1alpha1\nkind: GVKManifest\nmetadata:\n  name: gvkmanifest\nspec:\n  groups:\n  - name: "group1"\n    versions:\n    - name: "v1"\n      kinds: ["Kind1", "Kind2"]\n    - name: "v2"\n      kinds: ["Kind1", "Kind3"]\n  - name: "group2"\n    versions:\n      - name: "v1beta1"\n        kinds: ["Kind4", "Kind5"]\n')),(0,r.yg)("p",null,"Optionally, the ",(0,r.yg)("inlineCode",{parentName:"p"},"--omit-gvk-manifest")," flag can be used to skip the requirement of providing a manifest of supported GVKs for the cluster. If this is provided, all GVKs will be assumed to be supported by the cluster. If this assumption is not true, then the given config and templates may cause caching errors or incorrect evaluation on the cluster despite passing this command."),(0,r.yg)("h4",{id:"exit-codes-1"},"Exit Codes"),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"gator sync test")," will return a ",(0,r.yg)("inlineCode",{parentName:"p"},"0")," exit status when the Templates, SyncSets, and\nConfig are successfully ingested and all requirements are fulfilled."),(0,r.yg)("p",null,"An error during evaluation, for example a failure to read a file, will result in\na ",(0,r.yg)("inlineCode",{parentName:"p"},"1")," exit status with an error message printed to stderr."),(0,r.yg)("p",null,"Unfulfilled requirements will generate a ",(0,r.yg)("inlineCode",{parentName:"p"},"1")," exit status as well, and the unfulfilled requirements per template will be printed to stderr, like so:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre"},"the following requirements were not met:\ntemplatename1:\n- extensions/v1beta1:Ingress\n- networking.k8s.io/v1beta1:Ingress OR networking.k8s.io/v1:Ingress\ntemplatename2:\n- apps/v1:Deployment\ntemplatename3:\n- /v1:Service\n")),(0,r.yg)("h2",{id:"the-gator-bench-subcommand"},"The ",(0,r.yg)("inlineCode",{parentName:"h2"},"gator bench")," subcommand"),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"gator bench")," measures the performance of Gatekeeper policy evaluation. It loads ConstraintTemplates, Constraints, and Kubernetes resources, then repeatedly evaluates the resources against the constraints to gather latency and throughput metrics."),(0,r.yg)("admonition",{type:"note"},(0,r.yg)("p",{parentName:"admonition"},(0,r.yg)("inlineCode",{parentName:"p"},"gator bench")," measures ",(0,r.yg)("strong",{parentName:"p"},"compute-only")," policy evaluation latency, which does not include network round-trip time, TLS overhead, or Kubernetes API server processing. Real-world webhook latency will be higher. Use these metrics for relative comparisons between policy versions, not as absolute production latency predictions.")),(0,r.yg)("p",null,"This command is useful for:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Policy developers"),": Testing policy performance before deployment"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Platform teams"),": Comparing Rego vs CEL engine performance"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"CI/CD pipelines"),": Detecting performance regressions between releases")),(0,r.yg)("h3",{id:"usage-4"},"Usage"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},"gator bench --filename=policies/\n")),(0,r.yg)("h4",{id:"flags"},"Flags"),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:null},"Flag"),(0,r.yg)("th",{parentName:"tr",align:null},"Short"),(0,r.yg)("th",{parentName:"tr",align:null},"Default"),(0,r.yg)("th",{parentName:"tr",align:null},"Description"))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"--filename")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"-f")),(0,r.yg)("td",{parentName:"tr",align:null}),(0,r.yg)("td",{parentName:"tr",align:null},"File or directory containing ConstraintTemplates, Constraints, and resources. Repeatable.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"--image")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"-i")),(0,r.yg)("td",{parentName:"tr",align:null}),(0,r.yg)("td",{parentName:"tr",align:null},"OCI image URL containing policies. Repeatable.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"--engine")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"-e")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"cel")),(0,r.yg)("td",{parentName:"tr",align:null},"Policy engine to benchmark: ",(0,r.yg)("inlineCode",{parentName:"td"},"rego"),", ",(0,r.yg)("inlineCode",{parentName:"td"},"cel"),", or ",(0,r.yg)("inlineCode",{parentName:"td"},"all"))),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"--iterations")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"-n")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"1000")),(0,r.yg)("td",{parentName:"tr",align:null},"Number of benchmark iterations. Use \u22651000 for reliable P99 percentiles.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"--warmup")),(0,r.yg)("td",{parentName:"tr",align:null}),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"10")),(0,r.yg)("td",{parentName:"tr",align:null},"Warmup iterations before measurement")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"--concurrency")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"-c")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"1")),(0,r.yg)("td",{parentName:"tr",align:null},"Number of concurrent goroutines for parallel evaluation")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"--output")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"-o")),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"table")),(0,r.yg)("td",{parentName:"tr",align:null},"Output format: ",(0,r.yg)("inlineCode",{parentName:"td"},"table"),", ",(0,r.yg)("inlineCode",{parentName:"td"},"json"),", or ",(0,r.yg)("inlineCode",{parentName:"td"},"yaml"))),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"--memory")),(0,r.yg)("td",{parentName:"tr",align:null}),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"false")),(0,r.yg)("td",{parentName:"tr",align:null},"Enable memory profiling (estimates only, not GC-cycle accurate)")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"--save")),(0,r.yg)("td",{parentName:"tr",align:null}),(0,r.yg)("td",{parentName:"tr",align:null}),(0,r.yg)("td",{parentName:"tr",align:null},"Save results to file for future comparison")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"--compare")),(0,r.yg)("td",{parentName:"tr",align:null}),(0,r.yg)("td",{parentName:"tr",align:null}),(0,r.yg)("td",{parentName:"tr",align:null},"Compare against a baseline file")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"--threshold")),(0,r.yg)("td",{parentName:"tr",align:null}),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"10")),(0,r.yg)("td",{parentName:"tr",align:null},"Regression threshold percentage (for CI/CD)")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"--min-threshold")),(0,r.yg)("td",{parentName:"tr",align:null}),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"0")),(0,r.yg)("td",{parentName:"tr",align:null},"Minimum absolute latency difference to consider (e.g., ",(0,r.yg)("inlineCode",{parentName:"td"},"100\xb5s"),"). Useful for fast policies where percentage changes may be noise.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"--stats")),(0,r.yg)("td",{parentName:"tr",align:null}),(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"false")),(0,r.yg)("td",{parentName:"tr",align:null},"Gather detailed statistics from constraint framework")))),(0,r.yg)("h3",{id:"examples"},"Examples"),(0,r.yg)("h4",{id:"basic-benchmark"},"Basic Benchmark"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},"gator bench --filename=policies/\n")),(0,r.yg)("p",null,"Output:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre"},"=== Benchmark Results: Rego Engine ===\n\nConfiguration:\n  Templates:      5\n  Constraints:    10\n  Objects:        50\n  Iterations:     1000\n  Total Reviews:  50000\n\nTiming:\n  Setup Duration:  25.00ms\n    \u2514\u2500 Client Creation:       0.05ms\n    \u2514\u2500 Template Compilation:  20.00ms\n    \u2514\u2500 Constraint Loading:    3.00ms\n    \u2514\u2500 Data Loading:          1.95ms\n  Total Duration:  25.00s\n  Throughput:      2000.00 reviews/sec\n\nLatency (per review):\n  Min:   200.00\xb5s\n  Max:   5.00ms\n  Mean:  500.00\xb5s\n  P50:   450.00\xb5s\n  P95:   1.20ms\n  P99:   2.50ms\n\nResults:\n  Violations Found:  1500\n")),(0,r.yg)("h4",{id:"concurrent-benchmarking"},"Concurrent Benchmarking"),(0,r.yg)("p",null,"Simulate parallel load to test contention behavior:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},"gator bench --filename=policies/ --concurrency=4\n")),(0,r.yg)("p",null,"This runs 4 parallel goroutines each executing reviews concurrently."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre"},"=== Benchmark Results: Rego Engine ===\n\nConfiguration:\n  Templates:      5\n  Constraints:    10\n  Objects:        50\n  Iterations:     1000\n  Concurrency:    4\n  Total Reviews:  50000\n...\n")),(0,r.yg)("h4",{id:"compare-rego-vs-cel-engines"},"Compare Rego vs CEL Engines"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},"gator bench --filename=policies/ --engine=all\n")),(0,r.yg)("p",null,"This runs benchmarks for both engines and displays a comparison table:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre"},"=== Engine Comparison ===\n\nMetric         Rego        CEL\n------         ------      ------\nTemplates      5           5\nConstraints    10          10\nSetup Time     25.00ms     15.00ms\nThroughput     2000/sec    3500/sec\nMean Latency   500.00\xb5s    285.00\xb5s\nP95 Latency    1.20ms      600.00\xb5s\nP99 Latency    2.50ms      900.00\xb5s\nViolations     150         150\n\nPerformance: CEL is 1.75x faster than Rego\n")),(0,r.yg)("admonition",{type:"note"},(0,r.yg)("p",{parentName:"admonition"},"Templates without CEL code will be skipped when benchmarking the CEL engine.\nA warning will be displayed indicating which templates were skipped.")),(0,r.yg)("admonition",{type:"caution"},(0,r.yg)("p",{parentName:"admonition"},"The CEL engine does not support referential constraints. Referential data loading\nis skipped entirely when benchmarking with CEL\u2014this is expected behavior, not an error.\nIf you have policies that rely on referential data (e.g., checking if a namespace exists),\nthose constraints will not be fully exercised during CEL benchmarks. An informational note\nwill be displayed indicating that referential data is not supported by the CEL engine.")),(0,r.yg)("h4",{id:"memory-profiling"},"Memory Profiling"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},"gator bench --filename=policies/ --memory\n")),(0,r.yg)("p",null,"Adds memory statistics to the output:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre"},"Memory (estimated):\n  Allocs/Review:  3000\n  Bytes/Review:   150.00 KB\n  Total Allocs:   15000000\n  Total Bytes:    732.42 MB\n")),(0,r.yg)("admonition",{type:"caution"},(0,r.yg)("p",{parentName:"admonition"},"Memory statistics are estimates based on ",(0,r.yg)("inlineCode",{parentName:"p"},"runtime.MemStats")," captured before and after benchmark runs. They do not account for garbage collection cycles that may occur during benchmarking. For production memory analysis, use Go's pprof profiler.")),(0,r.yg)("h4",{id:"save-and-compare-baselines"},"Save and Compare Baselines"),(0,r.yg)("p",null,"Save benchmark results as a baseline:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},"gator bench --filename=policies/ --memory --save=baseline.json\n")),(0,r.yg)("p",null,"Compare future runs against the baseline:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},"gator bench --filename=policies/ --memory --compare=baseline.json\n")),(0,r.yg)("p",null,"Output includes a comparison table:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre"},"=== Baseline Comparison: Rego Engine ===\n\nMetric         Baseline     Current      Delta   Status\n------         --------     -------      -----   ------\nP50 Latency    450.00\xb5s     460.00\xb5s     +2.2%   \u2713\nP95 Latency    1.20ms       1.25ms       +4.2%   \u2713\nP99 Latency    2.50ms       2.60ms       +4.0%   \u2713\nMean Latency   500.00\xb5s     510.00\xb5s     +2.0%   \u2713\nThroughput     2000/sec     1960/sec     -2.0%   \u2713\nAllocs/Review  3000         3050         +1.7%   \u2713\nBytes/Review   150.00 KB    152.00 KB    +1.3%   \u2713\n\n\u2713 No significant regressions (threshold: 10.0%)\n")),(0,r.yg)("p",null,"For fast policies (< 1ms), small percentage changes may be noise. Use ",(0,r.yg)("inlineCode",{parentName:"p"},"--min-threshold")," to set an absolute minimum difference:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},"gator bench --filename=policies/ --compare=baseline.json --threshold=10 --min-threshold=100\xb5s\n")),(0,r.yg)("p",null,"This marks a metric as passing if either:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"The percentage change is within the threshold (10%), OR"),(0,r.yg)("li",{parentName:"ul"},"The absolute difference is less than the min-threshold (100\xb5s)")),(0,r.yg)("h3",{id:"cicd-integration"},"CI/CD Integration"),(0,r.yg)("p",null,"Use ",(0,r.yg)("inlineCode",{parentName:"p"},"gator bench")," in CI/CD pipelines to detect performance regressions automatically."),(0,r.yg)("h4",{id:"github-actions-example"},"GitHub Actions Example"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},"name: Policy Benchmark\n\non:\n  pull_request:\n    paths:\n      - 'policies/**'\n\njobs:\n  benchmark:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Download baseline\n        uses: actions/download-artifact@v4\n        with:\n          name: benchmark-baseline\n          path: .\n        continue-on-error: true  # First run won't have baseline\n\n      - name: Install gator\n        run: |\n          go install github.com/open-policy-agent/gatekeeper/v3/cmd/gator@latest\n\n      - name: Run benchmark\n        run: |\n          if [ -f baseline.json ]; then\n            # Use min-threshold to avoid flaky failures on fast policies\n            gator bench -f policies/ --memory \\\n              --compare=baseline.json \\\n              --threshold=10 \\\n              --min-threshold=100\xb5s\n          else\n            gator bench -f policies/ --memory --save=baseline.json\n          fi\n\n      - name: Upload baseline\n        if: github.ref == 'refs/heads/main'\n        uses: actions/upload-artifact@v4\n        with:\n          name: benchmark-baseline\n          path: baseline.json\n")),(0,r.yg)("admonition",{type:"tip"},(0,r.yg)("p",{parentName:"admonition"},"Use ",(0,r.yg)("inlineCode",{parentName:"p"},"--min-threshold")," in CI to prevent flaky failures. For policies that evaluate in under 1ms, a 10% regression might only be 50\xb5s of noise from system jitter.")),(0,r.yg)("h4",{id:"exit-codes-2"},"Exit Codes"),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:null},"Exit Code"),(0,r.yg)("th",{parentName:"tr",align:null},"Meaning"))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"0")),(0,r.yg)("td",{parentName:"tr",align:null},"Benchmark completed successfully, no regressions detected")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("inlineCode",{parentName:"td"},"1")),(0,r.yg)("td",{parentName:"tr",align:null},"Error occurred, or regression threshold exceeded (when using ",(0,r.yg)("inlineCode",{parentName:"td"},"--compare"),")")))),(0,r.yg)("p",null,"When ",(0,r.yg)("inlineCode",{parentName:"p"},"--compare")," is used with ",(0,r.yg)("inlineCode",{parentName:"p"},"--threshold"),", the command exits with code ",(0,r.yg)("inlineCode",{parentName:"p"},"1")," if any metric regresses beyond the threshold. This enables CI/CD pipelines to fail builds that introduce performance regressions."),(0,r.yg)("h3",{id:"understanding-metrics"},"Understanding Metrics"),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:null},"Metric"),(0,r.yg)("th",{parentName:"tr",align:null},"Description"))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"P50/P95/P99 Latency")),(0,r.yg)("td",{parentName:"tr",align:null},"Percentile latencies per review. P99 of 2ms means 99% of reviews complete in \u22642ms. Use \u22651000 iterations for reliable P99.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"Mean Latency")),(0,r.yg)("td",{parentName:"tr",align:null},"Average time per review")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"Throughput")),(0,r.yg)("td",{parentName:"tr",align:null},"Reviews processed per second")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"Allocs/Review")),(0,r.yg)("td",{parentName:"tr",align:null},"Memory allocations per review (with ",(0,r.yg)("inlineCode",{parentName:"td"},"--memory"),"). Estimate only.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"Bytes/Review")),(0,r.yg)("td",{parentName:"tr",align:null},"Bytes allocated per review (with ",(0,r.yg)("inlineCode",{parentName:"td"},"--memory"),"). Estimate only.")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"Setup Duration")),(0,r.yg)("td",{parentName:"tr",align:null},"Time to load templates, constraints, and data")))),(0,r.yg)("h4",{id:"setup-duration-breakdown"},"Setup Duration Breakdown"),(0,r.yg)("p",null,"Setup duration includes:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Client Creation"),": Initializing the constraint client"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Template Compilation"),": Compiling Rego/CEL code in ConstraintTemplates"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Constraint Loading"),": Adding constraints to the client"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Data Loading"),": Loading all Kubernetes resources into the data cache")),(0,r.yg)("admonition",{type:"note"},(0,r.yg)("p",{parentName:"admonition"},"Data loading adds all provided resources to the constraint client's cache. This is intentional behavior that matches how Gatekeeper evaluates referential constraints\u2014policies that reference other cluster resources (e.g., checking if a namespace exists) need this cached data available during evaluation.")),(0,r.yg)("h4",{id:"performance-guidance"},"Performance Guidance"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"P99 latency < 100ms")," is recommended for production admission webhooks"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"CEL is typically faster than Rego")," for equivalent policies"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"High memory allocations")," may indicate inefficient policy patterns"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Setup time")," matters for cold starts; consider template compilation cost"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Concurrency testing")," (",(0,r.yg)("inlineCode",{parentName:"li"},"--concurrency=N"),") reveals contention issues not visible in sequential runs")),(0,r.yg)("h3",{id:"performance-characteristics"},"Performance Characteristics"),(0,r.yg)("p",null,"The following characteristics are based on architectural differences between policy engines and general benchmarking principles. Actual numbers will vary based on policy complexity, hardware, and workload."),(0,r.yg)("admonition",{type:"tip"},(0,r.yg)("p",{parentName:"admonition"},"These insights were generated using the data gathering scripts in the Gatekeeper repository:"),(0,r.yg)("ul",{parentName:"admonition"},(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("a",{parentName:"li",href:"https://github.com/open-policy-agent/gatekeeper/blob/master/test/gator/bench/scripts/gather-data.sh"},(0,r.yg)("inlineCode",{parentName:"a"},"test/gator/bench/scripts/gather-data.sh"))," - Collects benchmark data across different scenarios"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("a",{parentName:"li",href:"https://github.com/open-policy-agent/gatekeeper/blob/master/test/gator/bench/scripts/analyze-data.sh"},(0,r.yg)("inlineCode",{parentName:"a"},"test/gator/bench/scripts/analyze-data.sh"))," - Analyzes and summarizes the collected data")),(0,r.yg)("p",{parentName:"admonition"},"You can run these scripts locally to validate these characteristics on your own hardware.")),(0,r.yg)("h4",{id:"cel-vs-rego"},"CEL vs Rego"),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:null},"Characteristic"),(0,r.yg)("th",{parentName:"tr",align:null},"CEL"),(0,r.yg)("th",{parentName:"tr",align:null},"Rego"))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"Evaluation Speed")),(0,r.yg)("td",{parentName:"tr",align:null},"1.5-3x faster"),(0,r.yg)("td",{parentName:"tr",align:null},"Baseline")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"Memory per Review")),(0,r.yg)("td",{parentName:"tr",align:null},"20-30% less"),(0,r.yg)("td",{parentName:"tr",align:null},"Baseline")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"Setup/Compilation")),(0,r.yg)("td",{parentName:"tr",align:null},"2-3x slower"),(0,r.yg)("td",{parentName:"tr",align:null},"Faster")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"Best For")),(0,r.yg)("td",{parentName:"tr",align:null},"Long-running processes"),(0,r.yg)("td",{parentName:"tr",align:null},"Cold starts")))),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Why the difference?")),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"CEL compiles to more efficient bytecode, resulting in faster evaluation"),(0,r.yg)("li",{parentName:"ul"},"Rego has lighter upfront compilation cost but slower per-evaluation overhead"),(0,r.yg)("li",{parentName:"ul"},"For admission webhooks (long-running), CEL's evaluation speed advantage compounds over time")),(0,r.yg)("h4",{id:"concurrency-scaling"},"Concurrency Scaling"),(0,r.yg)("admonition",{type:"note"},(0,r.yg)("p",{parentName:"admonition"},"The ",(0,r.yg)("inlineCode",{parentName:"p"},"--concurrency")," flag simulates parallel policy evaluation similar to how Kubernetes admission webhooks handle concurrent requests. In production, Gatekeeper processes multiple admission requests simultaneously, making concurrent benchmarking essential for realistic performance testing.")),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Linear scaling")," up to 4-8 concurrent workers"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Diminishing returns")," beyond CPU core count"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Increased P99 variance")," at high concurrency due to contention"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Recommendation"),": Use 4-8 workers for load testing; match production replica count")),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre"},"Concurrency   Typical Efficiency\n1             100% (baseline)\n2             85-95%\n4             70-85%\n8             50-70%\n16+           <50% (diminishing returns)\n")),(0,r.yg)("h4",{id:"benchmarking-best-practices"},"Benchmarking Best Practices"),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:null},"Practice"),(0,r.yg)("th",{parentName:"tr",align:null},"Recommendation"),(0,r.yg)("th",{parentName:"tr",align:null},"Why"))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"Iterations")),(0,r.yg)("td",{parentName:"tr",align:null},"\u22651000"),(0,r.yg)("td",{parentName:"tr",align:null},"Required for statistically meaningful P99 percentiles")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"Warmup")),(0,r.yg)("td",{parentName:"tr",align:null},"10 iterations"),(0,r.yg)("td",{parentName:"tr",align:null},"Go runtime stabilizes quickly; more warmup has minimal impact")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"Multiple Runs")),(0,r.yg)("td",{parentName:"tr",align:null},"3-5 runs"),(0,r.yg)("td",{parentName:"tr",align:null},"Expect 2-8% variance between identical runs")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"P99 vs Mean")),(0,r.yg)("td",{parentName:"tr",align:null},"Focus on P99 for SLAs"),(0,r.yg)("td",{parentName:"tr",align:null},"P99 has higher variance (~8%) than mean (~2%)")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},(0,r.yg)("strong",{parentName:"td"},"CI Thresholds")),(0,r.yg)("td",{parentName:"tr",align:null},"Use ",(0,r.yg)("inlineCode",{parentName:"td"},"--min-threshold")),(0,r.yg)("td",{parentName:"tr",align:null},"Prevents flaky failures from natural variance")))),(0,r.yg)("h4",{id:"interpreting-results"},"Interpreting Results"),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Healthy patterns:")),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"P95/P99 within 2-5x of P50 (consistent performance)"),(0,r.yg)("li",{parentName:"ul"},"Memory allocations stable across runs"),(0,r.yg)("li",{parentName:"ul"},"Throughput scales with concurrency up to core count")),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Warning signs:")),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"P99 > 10x P50 (high tail latency, possible GC pressure)"),(0,r.yg)("li",{parentName:"ul"},"Memory growing with iteration count (potential leak)"),(0,r.yg)("li",{parentName:"ul"},"Throughput decreasing at low concurrency (contention issue)"),(0,r.yg)("li",{parentName:"ul"},"Large variance between runs (noisy environment or unstable policy)")),(0,r.yg)("h2",{id:"bundling-policy-into-oci-artifacts"},"Bundling Policy into OCI Artifacts"),(0,r.yg)("p",null,"It may be useful to bundle policy files into OCI Artifacts for ingestion during\nCI/CD workflows. The workflow could perform validation on inbound objects using\n",(0,r.yg)("inlineCode",{parentName:"p"},"gator test|expand"),"."),(0,r.yg)("p",null,"A policy bundle can be composed of any arbitrary file structure, which ",(0,r.yg)("inlineCode",{parentName:"p"},"gator"),"\nwill walk recursively. Any files that do not end in ",(0,r.yg)("inlineCode",{parentName:"p"},"json|yaml|yml")," will be\nignored. ",(0,r.yg)("inlineCode",{parentName:"p"},"gator")," does not enforce any file schema in the artifacts; it only\nrequires that all files of the support extensions describe valid Kubernetes\nresources."),(0,r.yg)("p",null,"We recommend using the ",(0,r.yg)("a",{parentName:"p",href:"https://oras.land/docs/installation"},"Oras CLI")," to create OCI\nartifacts. For example, to push a bundle containing the 2 local directories\n",(0,r.yg)("inlineCode",{parentName:"p"},"constraints")," and ",(0,r.yg)("inlineCode",{parentName:"p"},"template_library"),":"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-shell"},"oras push localhost:5000/gator/policy-bundle:v1 ./constraints/:application/vnd.oci.image.layer.v1.tar+gzip \\\n  ./template_library/:application/vnd.oci.image.layer.v1.tar+gzip\n")),(0,r.yg)("p",null,"This expects that the ",(0,r.yg)("inlineCode",{parentName:"p"},"constraints")," and ",(0,r.yg)("inlineCode",{parentName:"p"},"template_library")," directories are at\nthe path that this command is being run from."),(0,r.yg)("h2",{id:"gotchas"},"Gotchas"),(0,r.yg)("h3",{id:"duplicate-violation-messages"},"Duplicate violation messages"),(0,r.yg)("p",null,"Rego de-duplicates identical violation messages. If you want to be sure that a\ntest returns multiple violations, use a unique message for each violation.\nOtherwise, if you specify an exact number of violations, the test may fail."),(0,r.yg)("h3",{id:"matching-is-case-sensitive"},"Matching is case-sensitive"),(0,r.yg)("p",null,"Message declarations are case-sensitive. If a test fails, check that the\nexpected message's capitalization exactly matches the one in the template."),(0,r.yg)("h3",{id:"referential-constraints-and-namespace-scoped-resources"},"Referential constraints and Namespace-scoped resources"),(0,r.yg)("p",null,"Gator cannot determine if a type is Namespace-scoped or not, so it does not\nassign objects to the default Namespace automatically. Always specify\n",(0,r.yg)("inlineCode",{parentName:"p"},"metadata.namespace")," for Namespace-scoped objects to prevent test failures, or\nto keep from specifying templates which will fail in a real cluster."),(0,r.yg)("h2",{id:"platform-compatibility"},"Platform Compatibility"),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"gator")," is only automatically tested on Linux for each commit. If you want to\nuse ",(0,r.yg)("inlineCode",{parentName:"p"},"gator")," on other systems, let us know by replying to\n",(0,r.yg)("a",{parentName:"p",href:"https://github.com/open-policy-agent/gatekeeper/issues/1655"},"this issue"),"."),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"gator verify")," has been manually tested on Windows and works as of\n",(0,r.yg)("a",{parentName:"p",href:"https://github.com/open-policy-agent/gatekeeper/commit/b3ed94406583c85f3102c54a32f362d27f76da96"},"this commit"),"\n. Continued functionality is not guaranteed."),(0,r.yg)("p",null,"File paths which include backslashes are not portable, so suites using such\npaths will not work as intended on Windows."))}c.isMDXComponent=!0}}]);